# This example shows how to deploy a Kimi AI 7B model server.
# The Kimi AI 7B server will provide inference services for the Kimi AI 7B model.
#
# NOTE: Using vllm-mock image for CI compatibility. Replace with actual Kimi AI image 
# once available and when deploying with GPU resources.

apiVersion: apps/v1
kind: Deployment
metadata:
  name: kimi-ai-7b
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kimi-ai-7b
  template:
    metadata:
      labels:
        app: kimi-ai-7b
    spec:
      containers:
        - name: llm-engine
          image: ghcr.io/yaozengzeng/vllm-mock:latest
          imagePullPolicy: IfNotPresent
          env:
            # specify the model name to mock
            - name: MODEL_NAME
              value: "moonshotai/Kimi-AI-7B"
          command:
            - python3
            - app.py
